version: "3.7"

services:
  mysql:
    image: mysql:5.7.31
    container_name: mysql
    #ports:
      #- "3301:3306"
    networks:
        movierec:
            ipv4_address: 172.19.0.2
    volumes:               
      - "./dockerMovieRec/mysql/conf:/etc/mysql/conf.d"
      - "./dockerMovieRec/mysql/logs:/logs"
      - "./dockerMovieRec/mysql/data:/var/lib/mysql"
    environment:
      MYSQL_ROOT_PASSWORD: "abc123456"
  tomcat:
    image: tomcat:8.5
    container_name: tomcat
    restart: always
    volumes: 
      - "./dockerMovieRec/tomcat/webapps:/usr/local/tomcat/webapps"
    links:
      - mysql
    depends_on:
      - mysql
    #ports:
      #- "8888:8080"
    networks:
        movierec:
            ipv4_address: 172.19.0.3
  nginx:
    restart: always
    image: nginx:1.19
    container_name: nginx
    ports:
      - 86:81
      - 85:80
      - 443:443
    depends_on:
      - tomcat
    volumes:
      - "./dockerMovieRec/nginx/conf.d:/etc/nginx/conf.d"
      - "./dockerMovieRec/nginx/nginx.conf:/etc/nginx/nginx.conf"
      - "./dockerMovieRec/nginx/log:/var/log/nginx"
      - "./dockerMovieRec/nginx/movielog:/var/log/movieLog"
      - "./dockerMovieRec/nginx/www:/var/www"
      - "./dockerMovieRec/nginx/etc/letsencrypt:/etc/letsencrypt"
    networks:
        movierec:
            ipv4_address: 172.19.0.4
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181"
    depends_on:
      - nginx
    networks:
        movierec:
            ipv4_address: 172.19.0.5
  kafka:
    image: wurstmeister/kafka:2.11-0.10.2.2
    container_name: kafka
    ports:
      - "9092"
    depends_on:
      - zookeeper
    links:
      - zookeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.19.0.6
      KAFKA_CREATE_TOPICS: "movielog:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    networks:
        movierec:
            ipv4_address: 172.19.0.6
  flume:
    image: xumj1996docker/flume
    container_name: flume
    depends_on:
      - kafka
    links:
      - kafka
    volumes:
      - ./dockerMovieRec/flume/conf:/usr/local/flume/apache-flume-1.7.0-bin/conf
      - ./dockerMovieRec/nginx/movielog:/nginx/movielog
      - ./dockerMovieRec/nginx/log:/nginx/log
    networks:
        movierec:
            ipv4_address: 172.19.0.7
  spark2:
    image: xumj1996docker/spark:v1
    container_name: spark2
    tty: true
    #ports:
      #- "28081:8081"
    depends_on:
      - flume
    networks:
        movierec:
            ipv4_address: 172.19.0.8
    volumes:               
      - "./dockerMovieRec/sparks/spark2/data:/data" #data volume
      - "./dockerMovieRec/sparks/spark_shared/conf:/usr/local/spark-1.6.2-bin-hadoop2.6/conf"
      - "./dockerMovieRec/sparks/hadoop_shared:/usr/local/hadoop-2.6.4/etc/hadoop"
      - "./dockerMovieRec/sparks/hosts:/etc/hosts"
      - "./dockerMovieRec/sparks/profile:/etc/profile"
  spark3:
    image: xumj1996docker/spark:v1
    container_name: spark3
    tty: true
    #ports:
      #- "38081:8081"
    depends_on:
      - spark2
    networks:
        movierec:
            ipv4_address: 172.19.0.9
    volumes:               
      - "./dockerMovieRec/sparks/spark3/data:/data" #data volume
      - "./dockerMovieRec/sparks/spark_shared/conf:/usr/local/spark-1.6.2-bin-hadoop2.6/conf"
      - "./dockerMovieRec/sparks/hadoop_shared:/usr/local/hadoop-2.6.4/etc/hadoop"
      - "./dockerMovieRec/sparks/hosts:/etc/hosts"
      - "./dockerMovieRec/sparks/profile:/etc/profile"
  spark1:
    image: xumj1996docker/spark:v1
    container_name: spark1
    tty: true
    #ports:
      #- "58080:8080"
      #- "54040:4040"
    depends_on:
      - spark3
    networks:
        movierec:
            ipv4_address: 172.19.0.10
    volumes:               
      - "./dockerMovieRec/sparks/spark1/data:/data" #data volume
      - "./dockerMovieRec/sparks/spark1/hive/conf:/usr/local/apache-hive-1.2.1-bin/conf" #master hive
      - "./dockerMovieRec/sparks/spark_shared/conf:/usr/local/spark-1.6.2-bin-hadoop2.6/conf"
      - "./dockerMovieRec/sparks/hadoop_shared:/usr/local/hadoop-2.6.4/etc/hadoop"
      - "./dockerMovieRec/sparks/hosts:/etc/hosts"
      - "./dockerMovieRec/sparks/profile:/etc/profile"
    environment:
      HADOOP_HOME: "/usr/local/hadoop-2.6.4/"
    command:
      - bash
      - -c 
      - |
        service ssh start
        /usr/local/hadoop-2.6.4/sbin/start-all.sh
        /usr/local/spark-1.6.2-bin-hadoop2.6/sbin/start-all.sh
        /usr/local/apache-hive-1.2.1-bin/bin/hive --service metastore -p 9083
        #/usr/local/spark-1.6.2-bin-hadoop2.6/bin/spark-submit --class com.cloud.streaming.SparkDrStreamALS --jars /lib/traintools/kafka-clients-0.8.2.0.jar,/lib/traintools/metrics-core-2.2.0.jar,/lib/traintools/kafka_2.10-0.8.2.1.jar,/lib/traintools/spark-streaming-kafka_2.10-1.6.2.jar,lib/mysql-connector-java-5.1.49-bin.jar /lib/traintools/SparkDrStreamALS.jar
networks:
   movierec:
      ipam:
         config:
         - subnet: 172.19.0.0/16
           gateway: 172.19.0.1
